{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 통계\n",
    "통계분석 및 검정 목차\n",
    "1. 기술통계 (Descriptive Statistics)\n",
    "중심 경향성 (Mean, Median, Mode)\n",
    "분산과 표준편차\n",
    "왜도와 첨도\n",
    "2. 확률분포 (Probability Distributions)\n",
    "이산 확률분포 (Bernoulli, Binomial, Poisson 등)\n",
    "연속 확률분포 (Normal, Exponential, Beta 등)\n",
    "3. 가설검정 (Hypothesis Testing)\n",
    "Z-test, T-test\n",
    "Chi-squared tests\n",
    "F-tests\n",
    "p-value, Confidence Interval\n",
    "4. 상관분석 (Correlation Analysis)\n",
    "Pearson Correlation\n",
    "Spearman Correlation\n",
    "Kendall Tau\n",
    "5. 회귀분석 (Regression Analysis)\n",
    "선형회귀 (Simple and Multiple)\n",
    "다항회귀 (Polynomial Regression up to 3rd degree)\n",
    "로지스틱 회귀 (Logistic Regression)\n",
    "6. 분산분석 (Analysis of Variance - ANOVA)\n",
    "일원분산분석 (One-way ANOVA)\n",
    "이원분산분석 (Two-way ANOVA)\n",
    "7. 시계열 분석 (Time Series Analysis)\n",
    "ARIMA, SARIMA\n",
    "Seasonal Decomposition\n",
    "Trend Analysis\n",
    "8. 비모수 통계 (Non-Parametric Statistics)\n",
    "Mann-Whitney U Test\n",
    "Kruskal-Wallis Test\n",
    "9. 머신러닝 기법을 이용한 분석\n",
    "분류 (Classification)\n",
    "회귀 (Regression)\n",
    "군집화 (Clustering)\n",
    "10. 텍스트 마이닝 (Text Mining)\n",
    "Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "Topic Modeling (LDA, NMF)\n",
    "Sentiment Analysis\n",
    "11. 고급 통계기법\n",
    "A/B Testing\n",
    "Bayesian Statistics\n",
    "Survival Analysis\n",
    "12. 클래스 불균형 처리 (Class Imbalance)\n",
    "Resampling Methods (Up-sampling, Down-sampling)\n",
    "Cost-sensitive Learning\n",
    "Synthetic Minority Over-sampling Technique (SMOTE)\n",
    "13. 분산 검정 및 모델 검증 (Variance Test and Model Validation)\n",
    "K-Fold Cross-Validation\n",
    "ROC, AUC\n",
    "Confusion Matrix\n",
    "14. 결과 해석 및 보고서 작성\n",
    "Data Storytelling\n",
    "Interpretation of Statistical Models\n",
    "Report Writing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 기술통계\n",
    "### 1.1. 중심 경향성 (Central Tendency)\n",
    "- 기본 pandas 지원 중심경향 확인\n",
    "```python\n",
    "df.describe(include='all') # 모든 컬럼에 대한 기술통계량 출력(min, max, mean, std, quartile, etc.)\n",
    "df.mean() # 산술평균\n",
    "df.median() # 중앙값\n",
    "df.mode() # 최빈값\n",
    "df.quantile([0.25, 0.5, 0.75]) # 4분위수\n",
    "np.percentile(df, [25, 50, 75]) # 백분위수\n",
    "```\n",
    "- scipy를 이용한 중심경향 심화\n",
    "```python\n",
    "from scipy.stats.mstats import gmean, hmean, tmean # 기하평균, 조화평균, 절사평균\n",
    "import numpy as np\n",
    "np.mean(df) # 산술평균\n",
    "gmean(df) # 기하평균\n",
    "hmean(df) # 조화평균\n",
    "tmean(df, limits=(10, 90)) # 절사평균\n",
    "np.sqrt(np.mean(df**2)) # 평방평균\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. 분산과 표준편차\n",
    "```python\n",
    "df.var(ddof=1) # 분산, ddof=1은 표본분산, ddof=0은 모분산\n",
    "df.std(ddof=1) # 표준편차, ddof=1은 표본표준편차, ddof=0은 모표준편차\n",
    "np.var(df, ddof=1) # numpy를 이용한 분산\n",
    "np.cov(df) # 공분산\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. 왜도와 첨도\n",
    "```python\n",
    "from scipy.stats import skew, kurtosis\n",
    "skew(df['col'], bias=False) # 왜도, bias=False는 표본왜도, bias=True는 모왜도 (default)\n",
    "df['col'].skew() # pandas를 이용한 왜도, bias=False인 표본왜도와 동일\n",
    "kurtosis(df['col'], bias=False) # 첨도, bias=False는 표본첨도, bias=True는 모첨도 (default)\n",
    "df['col'].kurtosis() # pandas를 이용한 첨도, bias=False인 표본첨도와 동일\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. 상관계수\n",
    "```python\n",
    "df.corr() # 상관계수 행렬, default는 피어슨 상관계수\n",
    "df.corr(method='spearman') # 스피어만 상관계수\n",
    "df.corr(method='kendall') # 켄달 상관계수\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "# 모두 (상관계수, p-value)가 출력되므로 corr, p = pearsonr(df['col1'], df['col2'])로 받아서 사용하는 것이 좋음\n",
    "pearsonr(df['col1'], df['col2']) # 피어슨 상관계수 (연속형, 선형)\n",
    "spearmanr(df['col1'], df['col2']) # 스피어만 상관계수 (순서형, 비선형)\n",
    "kendalltau(df['col1'], df['col2']) # 켄달 상관계수 (순서형, 작은 데이터셋)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 확률분포\n",
    "### 이산 확률분포\n",
    "#### 1.5.1. 베르누이 분포\n",
    "```python\n",
    "from scipy.stats import bernoulli, binom, poisson\n",
    "# 베르누이 분포 (성공/실패로 이루어진 이항 시행의 확률분포)\n",
    "bernoulli.rvs(size=10, p=0.3) # 0.3의 확률로 1이 나오는 베르누이 시행을 10번 수행 rvs: random variable sampling, 리스트로 각 시행의 결과를 출력\n",
    "bernoulli.pmf(k=1, p=0.3) # 0.3의 확률로 1이 나오는 베르누이 시행의 확률질량함수 pmf: probability mass function, k는 1이 나올 확률을 구하는 것(p가 0.3이므로 0.3이 출력됨)\n",
    "bernoulli.cdf(k=1, p=0.3) # 0.3의 확률로 1이 나오는 베르누이 시행의 누적분포함수 cdf: cumulative distribution function, k는 1이하가 나올 확률을 구하는 것(p가 0.3이므로 1이하가 나올 확률은 1이므로 1이 출력됨)\n",
    "bernoulli.mean(p=0.3) # 0.3의 확률로 1이 나오는 베르누이 시행의 기대값, 0.3이 출력됨\n",
    "bernoulli.var(p=0.3) # 0.3의 확률로 1이 나오는 베르누이 시행의 분산\n",
    "bernoulli.std(p=0.3) # 0.3의 확률로 1이 나오는 베르누이 시행의 표준편차\n",
    "E, V = bernoulli.stats(p=0.3, moments='mv') # 0.3의 확률로 1이 나오는 베르누이 시행의 기대값과 분산, moments='mv'는 mean, variance 다른옵션: 'm' mean, 'v' variance, 's' skewness, 'k' kurtosis\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.2. 이항 분포\n",
    "```python\n",
    "# 이항 분포 (베르누이 시행을 n번 수행하여 성공한 횟수의 확률분포, n>20이면 B(n,p)를 N(np, npq)인 정규분포로 근사할 수 있음)\n",
    "binom.rvs(size=10, n=20, p=0.3) # 20번 시행하여 0.3의 확률로 1이 나오는 이항 시행을 10번 수행, 즉 list로 10개의 이항 시행의 결과(성공 횟수)를 출력.e.g. [6, 7, 5, 6, 6, 6, 6, 6, 6, 6]\n",
    "binom.pmf(k=1, n=20, p=0.3) # 20번 시행하여 0.3의 확률로 1이 나오는 이항 시행의 확률질량함수 (0.3확률로 20번 시행시 1번 성공할 확률)\n",
    "binom.cdf(k=4, n=20, p=0.3) # 20번 시행하여 0.3의 확률로 1이 나오는 이항 시행의 누적분포함수 (0.3확률로 20번 시행시 4번 이하 성공할 확률)\n",
    "E, V = binom.stats(n=20, p=0.3, moments='mv') # 20번 시행하여 0.3의 확률로 1이 나오는 이항 시행의 기대값과 분산\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5의 확률로 5번 시행하여 3번 성공할 확률: 0.3125\n",
      "0.5의 확률로 5번 시행하여 3번 이하 성공할 확률: 0.8125\n",
      "0.5의 확률로 20번 시행 결과 성공 횟수 기댓값: 10.0000, 분산: 5.0000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "print(f'0.5의 확률로 5번 시행하여 3번 성공할 확률: {binom.pmf(k=3, n=5, p=0.5):.4f}')\n",
    "print(f'0.5의 확률로 5번 시행하여 3번 이하 성공할 확률: {binom.cdf(k=3, n=5, p=0.5):.4f}')\n",
    "print(f'0.5의 확률로 20번 시행 결과 성공 횟수 기댓값: {binom.stats(n=20, p=0.5)[0]:.4f}, 분산: {binom.stats(n=20, p=0.5)[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.3. 음이항 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5의 확률로 5번의 성공을 얻기 위해 추가로 필요한 시행 횟수를 10번 반복하여 샘플링: [ 9  2  5  6  2  4 10  4  7  2]\n",
      "0.5의 확률로 5번의 성공을 얻기 위해 추가로 10번의 시행이 필요한 확률: 0.0305\n",
      "0.5의 확률로 5번의 성공을 얻기 위해 추가로 10번 이하의 시행이 필요한 확률: 0.9408\n",
      "0.5의 확률로 5번의 성공을 얻기 위해 추가로 필요한 시행 횟수의 기댓값: 5.0000, 분산: 10.0000\n"
     ]
    }
   ],
   "source": [
    "# 음이항 분포 (성공 확률이 p인 베르누이 시행에서 r번의 성공을 얻기 위해 추가로 필요한 시행 횟수의 확률분포)\n",
    "from scipy.stats import nbinom\n",
    "print(f'0.5의 확률로 5번의 성공을 얻기 위해 추가로 필요한 시행 횟수를 10번 반복하여 샘플링: {nbinom.rvs(n=5, p=0.5, size=10)}')\n",
    "print(f'0.5의 확률로 5번의 성공을 얻기 위해 추가로 10번의 시행이 필요한 확률: {nbinom.pmf(k=10, n=5, p=0.5):.4f}')\n",
    "print(f'0.5의 확률로 5번의 성공을 얻기 위해 추가로 10번 이하의 시행이 필요한 확률: {nbinom.cdf(k=10, n=5, p=0.5):.4f}')\n",
    "E, V = nbinom.stats(n=5, p=0.5, moments='mv')\n",
    "print(f'0.5의 확률로 5번의 성공을 얻기 위해 추가로 필요한 시행 횟수의 기댓값: {E:.4f}, 분산: {V:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.4 기하 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5의 확률로 첫 성공까지 3번의 시행이 필요한 확률: 0.1250\n",
      "0.5의 확률로 첫 성공까지 3번 이하의 시행이 필요한 확률: 0.8750\n",
      "0.5의 확률로 첫 성공까지 필요한 시행 횟수의 기댓값: 2.0000, 분산: 2.0000\n"
     ]
    }
   ],
   "source": [
    "# 기하 분포 (성공 확률이 p인 베르누이 시행에서 첫 성공까지 필요한 시행 횟수의 확률분포)\n",
    "from scipy.stats import geom\n",
    "print(f'0.5의 확률로 첫 성공까지 3번의 시행이 필요한 확률: {geom.pmf(k=3, p=0.5):.4f}')\n",
    "print(f'0.5의 확률로 첫 성공까지 3번 이하의 시행이 필요한 확률: {geom.cdf(k=3, p=0.5):.4f}')\n",
    "print(f'0.5의 확률로 첫 성공까지 필요한 시행 횟수의 기댓값: {geom.stats(p=0.5)[0]:.4f}, 분산: {geom.stats(p=0.5)[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.5 초기하 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 100개 중 20개가 성공, 10개를 뽑았을 때 5개가 성공할 확률: 0.0215\n",
      "전체 100개 중 20개가 성공, 10개를 뽑았을 때 5개 이하가 성공할 확률: 0.9961\n",
      "전체 100개 중 20개가 성공, 10개를 뽑았을 때 성공 횟수 기댓값: 2.0000, 분산: 1.4545\n"
     ]
    }
   ],
   "source": [
    "# 초기하 분포 (유한한 모집단 M에서 N개를 무작위 비복원 추출할 때, 그 중 성공인 n개를 얻을 확률분포)\n",
    "#e.g. 상자 속에 100개의 공이 있고, 그 중 20개가 빨간공, 80개가 파란공이라고 할 때, 10개를 뽑았을 때 빨간공이 5개일 확률\n",
    "from scipy.stats import hypergeom\n",
    "print(f'전체 100개 중 20개가 성공, 10개를 뽑았을 때 5개가 성공할 확률: {hypergeom.pmf(k=5, M=100, n=20, N=10):.4f}')\n",
    "print(f'전체 100개 중 20개가 성공, 10개를 뽑았을 때 5개 이하가 성공할 확률: {hypergeom.cdf(k=5, M=100, n=20, N=10):.4f}')\n",
    "print(f'전체 100개 중 20개가 성공, 10개를 뽑았을 때 성공 횟수 기댓값: {hypergeom.stats(M=100, n=20, N=10)[0]:.4f}, 분산: {hypergeom.stats(M=100, n=20, N=10)[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.6 포아송 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 발생 빈도가 3일 때, 5번 발생할 확률: 0.1008\n",
      "평균 발생 빈도가 3일 때, 5번 이하로 발생할 확률: 0.9161\n",
      "평균 발생 빈도가 3일 때, 발생 횟수의 기댓값: 3.0000, 분산: 3.0000\n"
     ]
    }
   ],
   "source": [
    "# 포아송 분포 (단위 시간/공간에서 발생하는 사건의 횟수)\n",
    "# e.g. 하루 평균 3건의 사고가 발생하는 교차로에서, 하루에 실제로 5건의 사고가 발생할 확률.\n",
    "from scipy.stats import poisson\n",
    "print(f'평균 발생 빈도가 3일 때, 5번 발생할 확률: {poisson.pmf(k=5, mu=3):.4f}')\n",
    "print(f'평균 발생 빈도가 3일 때, 5번 이하로 발생할 확률: {poisson.cdf(k=5, mu=3):.4f}')\n",
    "print(f'평균 발생 빈도가 3일 때, 발생 횟수의 기댓값: {poisson.stats(mu=3)[0]:.4f}, 분산: {poisson.stats(mu=3)[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연속 확률분포"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.7 균일 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1~6 사이의 숫자가 나올 확률이 동일한 주사위를 던졌을 때, 숫자 2가 나올 확률 : 0.1667\n"
     ]
    }
   ],
   "source": [
    "# 균일 분포 (지정된 범위 내에서 모든 값이 나올 확률이 동일한 분포)\n",
    "# e.g. 1~6 사이의 숫자가 나올 확률이 동일한 주사위를 던졌을 때, 1~6 사이의 숫자가 나올 확률\n",
    "from scipy.stats import uniform\n",
    "print(f'1~6 사이의 숫자가 나올 확률이 동일한 주사위를 던졌을 때, 숫자 2가 나올 확률 : {uniform.pdf(x=2, loc=1, scale=6):.4f}') # loc: 시작점, scale: 범위, x: 확률변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.8 정규 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균이 2이고 표준편차가 3인 정규분포에서, 1~3 사이의 값이 나올 확률: 0.2611\n",
      "평균이 2이고 표준편차가 3인 정규분포에서 랜덤으로 하나를 뽑은 숫자: 1.9263122078179824\n",
      "평균이 2이고 표준편차가 3인 정규분포에서, 1이하의 값이 나올 확률: 0.3694\n"
     ]
    }
   ],
   "source": [
    "# 정규 분포 (평균과 표준편차로 모양이 결정되는 종 모양의 분포)\n",
    "# e.g. 평균이 2이고 표준편차가 3인 정규분포에서, 1~3 사이의 값이 나올 확률\n",
    "from scipy.stats import norm\n",
    "print(f'평균이 2이고 표준편차가 3인 정규분포에서, 1~3 사이의 값이 나올 확률: {norm.cdf(x=3, loc=2, scale=3) - norm.cdf(x=1, loc=2, scale=3):.4f}') # loc: 평균, scale: 표준편차, x: 확률변수\n",
    "print(f'평균이 2이고 표준편차가 3인 정규분포에서 랜덤으로 하나를 뽑은 숫자: {norm.rvs(loc=2, scale=3, size=1)[0]}') # loc: 평균, scale: 표준편차, size: 샘플링 개수\n",
    "print(f'평균이 2이고 표준편차가 3인 정규분포에서, 1이하의 값이 나올 확률: {norm.cdf(x=1, loc=2, scale=3):.4f}') # loc: 평균, scale: 표준편차, x: 확률변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.9 표준정규분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균이 0이고 표준편차가 1인 정규분포에서, -1~1 사이의 값이 나올 확률: 0.6827\n"
     ]
    }
   ],
   "source": [
    "# 표준정규분포 (평균이 0이고 표준편차가 1인 정규분포)\n",
    "# e.g. 평균이 0이고 표준편차가 1인 정규분포에서, -1~1 사이의 값이 나올 확률\n",
    "from scipy.stats import norm\n",
    "print(f'평균이 0이고 표준편차가 1인 정규분포에서, -1~1 사이의 값이 나올 확률: {norm.cdf(x=1, loc=0, scale=1) - norm.cdf(x=-1, loc=0, scale=1):.4f}') # loc: 평균, scale: 표준편차, x: 확률변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.10 지수 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 다음 버스가 도착하는데 걸리는 시간이 5분일 확률: 0.0607\n",
      "평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 다음 버스가 도착하는데 걸리는 시간이 5분 이하일 확률: 0.3935\n",
      "평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 다음 버스가 도착하는데 걸리는 시간의 기댓값: 10.0000, 분산: 100.0000\n"
     ]
    }
   ],
   "source": [
    "# 지수분포 (포아송 분포가 단위 시간내 발생하는 사건의 횟수라면, 지수분포는 한 번의 사건이 발생하는데 걸리는 시간)\n",
    "# e.g. 평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 다음 버스가 도착하는데 걸리는 시간이 5분일 확률\n",
    "from scipy.stats import expon\n",
    "print(f'평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 다음 버스가 도착하는데 걸리는 시간이 5분일 확률: {expon.pdf(x=5, loc=0, scale=10):.4f}') # loc: 시작점, scale: 평균, x: 확률변수\n",
    "print(f'평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 다음 버스가 도착하는데 걸리는 시간이 5분 이하일 확률: {expon.cdf(x=5, loc=0, scale=10):.4f}') # loc: 시작점, scale: 평균, x: 확률변수\n",
    "print(f'평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 다음 버스가 도착하는데 걸리는 시간의 기댓값: {expon.stats(loc=0, scale=10)[0]:.4f}, 분산: {expon.stats(loc=0, scale=10)[1]:.4f}') # loc: 시작점, scale: 평균"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.11 감마 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 2개의 버스가 도착하는데 걸리는 시간이 15분일 확률: 0.0335\n",
      "평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 2개의 버스가 도착하는데 걸리는 시간이 15분 이하일 확률: 0.4422\n"
     ]
    }
   ],
   "source": [
    "# 감마분포 (지수분포의 확장으로, a번의 사건이 발생할 때까지 걸리는 시간의 분포)\n",
    "# e.g. 평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 2개의 버스가 도착하는데 걸리는 시간이 15분일 확률\n",
    "from scipy.stats import gamma\n",
    "print(f'평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 2개의 버스가 도착하는데 걸리는 시간이 15분일 확률: {gamma.pdf(x=15, a=2, loc=0, scale=10):.4f}') # loc: 시작점, scale: 평균, x: 확률변수, a: 형상 파라미터(2개의 버스)\n",
    "print(f'평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 2개의 버스가 도착하는데 걸리는 시간이 15분 이하일 확률: {gamma.cdf(x=15, a=2, loc=0, scale=10):.4f}') # loc: 시작점, scale: 평균, x: 확률변수, a: 형상 파라미터(2개의 버스)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.12 카이제곱 분포 및 검정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카이제곱 검정 결과 통계량: 2.0000, p-value: 0.8491\n",
      "카이제곱 검정 결과 통계량: 8.5952, p-value: 0.0034\n",
      "카이제곱 검정 결과 통계량: 26.7644, p-value: 0.0442\n"
     ]
    }
   ],
   "source": [
    "# 카이제곱 분포 (정규분포를 따르는 모집단에서 크기가 n인 표본을 무작위 반복 추출할 때, 각 표본의 분산을 합한 값의 분포)\n",
    "\n",
    "# 카이제곱 분포는 범주형 변수들의 적합도 검정, 독립성 검정, 동질성 검정에 사용됨\n",
    "# e.g. 주사위 던지기: 주사위를 100번 던졌을 때, 1~6 이 나온 횟수를 카이제곱 검정을 통해 주사위가 공정한지 검정 (적합도 검정)\n",
    "# e.g. 성별에 따른 흡연율: 남성 100명, 여성 100명을 대상으로 흡연 여부를 조사하여, 성별에 따라 흡연율이 다른지 검정 (독립성 검정)\n",
    "# e.g. 5개의 공장에서 동일한 제품을 생산하였을 때, 5개의 공장에서 생산된 제품의 품질이 동일한지 검정 (동질성 검정)\n",
    "\n",
    "# 적합도 검정\n",
    "from scipy.stats import chisquare\n",
    "cubic = [15, 20, 15, 20, 15, 15] # 주사위를 100번 던졌을 때, 1~6 이 나온 실제 횟수\n",
    "theoretical_cube = [100/6, 100/6, 100/6, 100/6, 100/6, 100/6] # 이론적으로 주사위를 100번 던졌을 때, 1~6 이 나올 확률 (동일)\n",
    "cubic_chi = chisquare(cubic, theoretical_cube) # 카이제곱 검정\n",
    "print(f'카이제곱 검정 결과 통계량: {cubic_chi[0]:.4f}, p-value: {cubic_chi[1]:.4f}') # p-value가 0.05보다 크므로 주사위는 공정하다고 할 수 있음\n",
    "\n",
    "# 독립성 검정\n",
    "from scipy.stats import chi2_contingency\n",
    "man_smoke = [40, 60]  # 남성 100명 중 흡연자 40명, 비흡연자 60명\n",
    "woman_smoke = [20, 80]  # 여성 100명 중 흡연자 20명, 비흡연자 80명\n",
    "smoking_table = [man_smoke, woman_smoke]\n",
    "chi2_val, p_val, dof, expected = chi2_contingency(smoking_table)\n",
    "print(f'카이제곱 검정 결과 통계량: {chi2_val:.4f}, p-value: {p_val:.4f}')  # p-value가 0.05보다 작으므로 성별에 따라 흡연율이 다르다고 할 수 있음\n",
    "\n",
    "# 동질성 검정\n",
    "from scipy.stats import chi2_contingency\n",
    "factory1 = [18, 7, 10, 15, 20] # 5개의 공장에서 생산된 제품의 품질\n",
    "factory2 = [10, 10, 20, 20, 10]\n",
    "factory3 = [20, 20, 20, 20, 20]\n",
    "factory4 = [10, 10, 20, 20, 10]\n",
    "factory5 = [20, 20, 10, 15, 15]\n",
    "quality_table = [factory1, factory2, factory3, factory4, factory5]\n",
    "chi2_val, p_val, dof, expected = chi2_contingency(quality_table)\n",
    "print(f'카이제곱 검정 결과 통계량: {chi2_val:.4f}, p-value: {p_val:.4f}') # p-value가 0.05보다 작으므로 5개의 공장에서 생산된 제품의 품질은 동일하다고 할 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.13 t 분포 및 검정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one sample t-검정 결과 통계량: 0.0000, p-value: 1.0000\n",
      "two sample t-검정 결과 통계량: 5.1113, p-value: 0.0001\n",
      "paired t-검정 결과 통계량: inf, p-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# t-분포 (집단의 평균을 비교할 때 사용, 특히 샘플 크기가 작을 때 유용)\n",
    "## 단일 표본 t-검정 (One-sample t-test)\n",
    "### e.g. 축구 선수 평균 키가 180cm인지 검정\n",
    "from scipy.stats import ttest_1samp\n",
    "soccer_height = [170, 175, 180, 185, 190]  # 5명의 축구 선수의 키\n",
    "t_stat, p_val = ttest_1samp(soccer_height, 180)\n",
    "print(f'one sample t-검정 결과 통계량: {t_stat:.4f}, p-value: {p_val:.4f}')  # p-value가 0.05보다 크므로 축구 선수 평균 키가 180cm이라고 할 수 있음\n",
    "\n",
    "## 두 독립 표본 t-검정 (Two-sample t-test)\n",
    "### e.g. 남성과 여성의 평균 키 비교\n",
    "from scipy.stats import ttest_ind\n",
    "male_height = [170, 175, 180, 185, 190, 175, 180, 185, 190, 195]  # 10명의 남성의 키\n",
    "female_height = [160, 165, 170, 175, 165, 158, 162, 166, 170, 175]  # 10명의 여성의 키\n",
    "t_stat, p_val = ttest_ind(male_height, female_height)\n",
    "print(f'two sample t-검정 결과 통계량: {t_stat:.4f}, p-value: {p_val:.4f}')  # p-value가 0.05보다 작으므로 두 집단의 평균이 다르다고 할 수 있음\n",
    "\n",
    "## 대응 표본 t-검정 (Paired t-test)\n",
    "### e.g. 특정 약을 복용하기 전과 후의 혈압 차이 검정\n",
    "from scipy.stats import ttest_rel\n",
    "before_drug = [120, 130, 125, 140, 145, 135, 130, 125, 140, 135]  # 약 복용 전 혈압\n",
    "after_drug = [110, 120, 115, 130, 135, 125, 120, 115, 130, 125]  # 약 복용 후 혈압\n",
    "t_stat, p_val = ttest_rel(before_drug, after_drug)\n",
    "print(f'paired t-검정 결과 통계량: {t_stat:.4f}, p-value: {p_val:.4f}')  # p-value가 0.05보다 작으므로 약 복용 전후의 혈압이 다르다고 할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.14 F 분포 및 ANOVA검정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-검정 결과 통계량: 5.7660, p-value: 0.0030\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1   group2  meandiff p-adj   lower    upper  reject\n",
      "---------------------------------------------------------\n",
      "factory1 factory2     -4.8 0.1991 -11.1562  1.5562  False\n",
      "factory1 factory3      5.2 0.1433  -1.1562 11.5562  False\n",
      "factory1 factory4     -0.2    1.0  -6.5562  6.1562  False\n",
      "factory1 factory5      1.6 0.9409  -4.7562  7.9562  False\n",
      "factory2 factory3     10.0 0.0011   3.6438 16.3562   True\n",
      "factory2 factory4      4.6 0.2328  -1.7562 10.9562  False\n",
      "factory2 factory5      6.4 0.0479   0.0438 12.7562   True\n",
      "factory3 factory4     -5.4 0.1206 -11.7562  0.9562  False\n",
      "factory3 factory5     -3.6 0.4591  -9.9562  2.7562  False\n",
      "factory4 factory5      1.8 0.9123  -4.5562  8.1562  False\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# F-분포 (두 모집단의 분산을 비교할 때 사용)\n",
    "# One way ANOVA 분석\n",
    "## e.g. 두 공장에서 생산된 제품의 품질 비교\n",
    "from scipy.stats import f_oneway\n",
    "factory1 = [18, 7, 10, 15, 20] # 5개의 공장에서 생산된 제품의 품질\n",
    "factory2 = [8, 11, 9, 6, 12]\n",
    "factory3 = [18, 20, 20, 18, 20]\n",
    "factory4 = [14, 13, 15, 13, 14]\n",
    "factory5 = [20, 20, 10, 13, 15]\n",
    "f_stat, p_val = f_oneway(factory1, factory2, factory3, factory4, factory5)\n",
    "print(f'F-검정 결과 통계량: {f_stat:.4f}, p-value: {p_val:.4f}') # p-value가 0.05보다 작으므로 5개의 공장에서 생산된 제품의 품질은 동일하다고 할 수 없음\n",
    "\n",
    "# 사후 검정 (Tukey HSD); ANOVA 분석 결과 귀무가설을 기각했을 때, 어떤 집단이 다른 집단과 다른지 검정\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import pandas as pd\n",
    "factory_df = pd.DataFrame({'quality': factory1 + factory2 + factory3 + factory4 + factory5, 'factory': ['factory1']*5 + ['factory2']*5 + ['factory3']*5 + ['factory4']*5 + ['factory5']*5})\n",
    "tukey = pairwise_tukeyhsd(factory_df['quality'], factory_df['factory'], alpha=0.05)\n",
    "print(tukey) # reject가 True인 경우, 두 집단의 평균이 다르다고 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
