{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 통계\n",
    "통계분석 및 검정 목차\n",
    "1. 기술통계 (Descriptive Statistics)\n",
    "중심 경향성 (Mean, Median, Mode)\n",
    "분산과 표준편차\n",
    "왜도와 첨도\n",
    "2. 확률분포 (Probability Distributions)\n",
    "이산 확률분포 (Bernoulli, Binomial, Poisson 등)\n",
    "연속 확률분포 (Normal, Exponential, Beta 등)\n",
    "3. 가설검정 (Hypothesis Testing)\n",
    "Z-test, T-test\n",
    "Chi-squared tests\n",
    "F-tests\n",
    "p-value, Confidence Interval\n",
    "4. 상관분석 (Correlation Analysis)\n",
    "Pearson Correlation\n",
    "Spearman Correlation\n",
    "Kendall Tau\n",
    "5. 회귀분석 (Regression Analysis)\n",
    "선형회귀 (Simple and Multiple)\n",
    "다항회귀 (Polynomial Regression up to 3rd degree)\n",
    "로지스틱 회귀 (Logistic Regression)\n",
    "6. 분산분석 (Analysis of Variance - ANOVA)\n",
    "일원분산분석 (One-way ANOVA)\n",
    "이원분산분석 (Two-way ANOVA)\n",
    "7. 시계열 분석 (Time Series Analysis)\n",
    "ARIMA, SARIMA\n",
    "Seasonal Decomposition\n",
    "Trend Analysis\n",
    "8. 비모수 통계 (Non-Parametric Statistics)\n",
    "Mann-Whitney U Test\n",
    "Kruskal-Wallis Test\n",
    "9. 머신러닝 기법을 이용한 분석\n",
    "분류 (Classification)\n",
    "회귀 (Regression)\n",
    "군집화 (Clustering)\n",
    "10. 텍스트 마이닝 (Text Mining)\n",
    "Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "Topic Modeling (LDA, NMF)\n",
    "Sentiment Analysis\n",
    "11. 고급 통계기법\n",
    "A/B Testing\n",
    "Bayesian Statistics\n",
    "Survival Analysis\n",
    "12. 클래스 불균형 처리 (Class Imbalance)\n",
    "Resampling Methods (Up-sampling, Down-sampling)\n",
    "Cost-sensitive Learning\n",
    "Synthetic Minority Over-sampling Technique (SMOTE)\n",
    "13. 분산 검정 및 모델 검증 (Variance Test and Model Validation)\n",
    "K-Fold Cross-Validation\n",
    "ROC, AUC\n",
    "Confusion Matrix\n",
    "14. 결과 해석 및 보고서 작성\n",
    "Data Storytelling\n",
    "Interpretation of Statistical Models\n",
    "Report Writing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 기술통계\n",
    "### 1.1. 중심 경향성 (Central Tendency)\n",
    "- 기본 pandas 지원 중심경향 확인\n",
    "```python\n",
    "df.describe(include='all') # 모든 컬럼에 대한 기술통계량 출력(min, max, mean, std, quartile, etc.)\n",
    "df.mean() # 산술평균\n",
    "df.median() # 중앙값\n",
    "df.mode() # 최빈값\n",
    "df.quantile([0.25, 0.5, 0.75]) # 4분위수\n",
    "np.percentile(df, [25, 50, 75]) # 백분위수\n",
    "```\n",
    "- scipy를 이용한 중심경향 심화\n",
    "```python\n",
    "from scipy.stats.mstats import gmean, hmean, tmean # 기하평균, 조화평균, 절사평균\n",
    "import numpy as np\n",
    "np.mean(df) # 산술평균\n",
    "gmean(df) # 기하평균\n",
    "hmean(df) # 조화평균\n",
    "tmean(df, limits=(10, 90)) # 절사평균\n",
    "np.sqrt(np.mean(df**2)) # 평방평균\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. 분산과 표준편차\n",
    "```python\n",
    "df.var(ddof=1) # 분산, ddof=1은 표본분산, ddof=0은 모분산\n",
    "df.std(ddof=1) # 표준편차, ddof=1은 표본표준편차, ddof=0은 모표준편차\n",
    "np.var(df, ddof=1) # numpy를 이용한 분산\n",
    "np.cov(df) # 공분산\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. 왜도와 첨도\n",
    "```python\n",
    "from scipy.stats import skew, kurtosis\n",
    "skew(df['col'], bias=False) # 왜도, bias=False는 표본왜도, bias=True는 모왜도 (default)\n",
    "df['col'].skew() # pandas를 이용한 왜도, bias=False인 표본왜도와 동일\n",
    "kurtosis(df['col'], bias=False) # 첨도, bias=False는 표본첨도, bias=True는 모첨도 (default)\n",
    "df['col'].kurtosis() # pandas를 이용한 첨도, bias=False인 표본첨도와 동일\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. 상관계수\n",
    "```python\n",
    "df.corr() # 상관계수 행렬, default는 피어슨 상관계수\n",
    "df.corr(method='spearman') # 스피어만 상관계수\n",
    "df.corr(method='kendall') # 켄달 상관계수\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "# 모두 (상관계수, p-value)가 출력되므로 corr, p = pearsonr(df['col1'], df['col2'])로 받아서 사용하는 것이 좋음\n",
    "pearsonr(df['col1'], df['col2']) # 피어슨 상관계수 (연속형, 선형)\n",
    "spearmanr(df['col1'], df['col2']) # 스피어만 상관계수 (순서형, 비선형)\n",
    "kendalltau(df['col1'], df['col2']) # 켄달 상관계수 (순서형, 작은 데이터셋)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 확률분포\n",
    "### 이산 확률분포\n",
    "#### 1.5.1. 베르누이 분포\n",
    "```python\n",
    "from scipy.stats import bernoulli, binom, poisson\n",
    "# 베르누이 분포 (성공/실패로 이루어진 이항 시행의 확률분포)\n",
    "bernoulli.rvs(size=10, p=0.3) # 0.3의 확률로 1이 나오는 베르누이 시행을 10번 수행 rvs: random variable sampling, 리스트로 각 시행의 결과를 출력\n",
    "bernoulli.pmf(k=1, p=0.3) # 0.3의 확률로 1이 나오는 베르누이 시행의 확률질량함수 pmf: probability mass function, k는 1이 나올 확률을 구하는 것(p가 0.3이므로 0.3이 출력됨)\n",
    "bernoulli.cdf(k=1, p=0.3) # 0.3의 확률로 1이 나오는 베르누이 시행의 누적분포함수 cdf: cumulative distribution function, k는 1이하가 나올 확률을 구하는 것(p가 0.3이므로 1이하가 나올 확률은 1이므로 1이 출력됨)\n",
    "bernoulli.mean(p=0.3) # 0.3의 확률로 1이 나오는 베르누이 시행의 기대값, 0.3이 출력됨\n",
    "bernoulli.var(p=0.3) # 0.3의 확률로 1이 나오는 베르누이 시행의 분산\n",
    "bernoulli.std(p=0.3) # 0.3의 확률로 1이 나오는 베르누이 시행의 표준편차\n",
    "E, V = bernoulli.stats(p=0.3, moments='mv') # 0.3의 확률로 1이 나오는 베르누이 시행의 기대값과 분산, moments='mv'는 mean, variance 다른옵션: 'm' mean, 'v' variance, 's' skewness, 'k' kurtosis\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.2. 이항 분포\n",
    "```python\n",
    "# 이항 분포 (베르누이 시행을 n번 수행하여 성공한 횟수의 확률분포, n>20이면 B(n,p)를 N(np, npq)인 정규분포로 근사할 수 있음)\n",
    "binom.rvs(size=10, n=20, p=0.3) # 20번 시행하여 0.3의 확률로 1이 나오는 이항 시행을 10번 수행, 즉 list로 10개의 이항 시행의 결과(성공 횟수)를 출력.e.g. [6, 7, 5, 6, 6, 6, 6, 6, 6, 6]\n",
    "binom.pmf(k=1, n=20, p=0.3) # 20번 시행하여 0.3의 확률로 1이 나오는 이항 시행의 확률질량함수 (0.3확률로 20번 시행시 1번 성공할 확률)\n",
    "binom.cdf(k=4, n=20, p=0.3) # 20번 시행하여 0.3의 확률로 1이 나오는 이항 시행의 누적분포함수 (0.3확률로 20번 시행시 4번 이하 성공할 확률)\n",
    "E, V = binom.stats(n=20, p=0.3, moments='mv') # 20번 시행하여 0.3의 확률로 1이 나오는 이항 시행의 기대값과 분산\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5의 확률로 5번 시행하여 3번 성공할 확률: 0.3125\n",
      "0.5의 확률로 5번 시행하여 3번 이하 성공할 확률: 0.8125\n",
      "0.5의 확률로 20번 시행 결과 성공 횟수 기댓값: 10.0000, 분산: 5.0000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "print(f'0.5의 확률로 5번 시행하여 3번 성공할 확률: {binom.pmf(k=3, n=5, p=0.5):.4f}')\n",
    "print(f'0.5의 확률로 5번 시행하여 3번 이하 성공할 확률: {binom.cdf(k=3, n=5, p=0.5):.4f}')\n",
    "print(f'0.5의 확률로 20번 시행 결과 성공 횟수 기댓값: {binom.stats(n=20, p=0.5)[0]:.4f}, 분산: {binom.stats(n=20, p=0.5)[1]:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.3. 음이항 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5의 확률로 5번의 성공을 얻기 위해 추가로 필요한 시행 횟수를 10번 반복하여 샘플링: [ 9  2  5  6  2  4 10  4  7  2]\n",
      "0.5의 확률로 5번의 성공을 얻기 위해 추가로 10번의 시행이 필요한 확률: 0.0305\n",
      "0.5의 확률로 5번의 성공을 얻기 위해 추가로 10번 이하의 시행이 필요한 확률: 0.9408\n",
      "0.5의 확률로 5번의 성공을 얻기 위해 추가로 필요한 시행 횟수의 기댓값: 5.0000, 분산: 10.0000\n"
     ]
    }
   ],
   "source": [
    "# 음이항 분포 (성공 확률이 p인 베르누이 시행에서 r번의 성공을 얻기 위해 추가로 필요한 시행 횟수의 확률분포)\n",
    "from scipy.stats import nbinom\n",
    "print(f'0.5의 확률로 5번의 성공을 얻기 위해 추가로 필요한 시행 횟수를 10번 반복하여 샘플링: {nbinom.rvs(n=5, p=0.5, size=10)}')\n",
    "print(f'0.5의 확률로 5번의 성공을 얻기 위해 추가로 10번의 시행이 필요한 확률: {nbinom.pmf(k=10, n=5, p=0.5):.4f}')\n",
    "print(f'0.5의 확률로 5번의 성공을 얻기 위해 추가로 10번 이하의 시행이 필요한 확률: {nbinom.cdf(k=10, n=5, p=0.5):.4f}')\n",
    "E, V = nbinom.stats(n=5, p=0.5, moments='mv')\n",
    "print(f'0.5의 확률로 5번의 성공을 얻기 위해 추가로 필요한 시행 횟수의 기댓값: {E:.4f}, 분산: {V:.4f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.4 기하 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5의 확률로 첫 성공까지 3번의 시행이 필요한 확률: 0.1250\n",
      "0.5의 확률로 첫 성공까지 3번 이하의 시행이 필요한 확률: 0.8750\n",
      "0.5의 확률로 첫 성공까지 필요한 시행 횟수의 기댓값: 2.0000, 분산: 2.0000\n"
     ]
    }
   ],
   "source": [
    "# 기하 분포 (성공 확률이 p인 베르누이 시행에서 첫 성공까지 필요한 시행 횟수의 확률분포)\n",
    "from scipy.stats import geom\n",
    "print(f'0.5의 확률로 첫 성공까지 3번의 시행이 필요한 확률: {geom.pmf(k=3, p=0.5):.4f}')\n",
    "print(f'0.5의 확률로 첫 성공까지 3번 이하의 시행이 필요한 확률: {geom.cdf(k=3, p=0.5):.4f}')\n",
    "print(f'0.5의 확률로 첫 성공까지 필요한 시행 횟수의 기댓값: {geom.stats(p=0.5)[0]:.4f}, 분산: {geom.stats(p=0.5)[1]:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.5 초기하 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 100개 중 20개가 성공, 10개를 뽑았을 때 5개가 성공할 확률: 0.0215\n",
      "전체 100개 중 20개가 성공, 10개를 뽑았을 때 5개 이하가 성공할 확률: 0.9961\n",
      "전체 100개 중 20개가 성공, 10개를 뽑았을 때 성공 횟수 기댓값: 2.0000, 분산: 1.4545\n"
     ]
    }
   ],
   "source": [
    "# 초기하 분포 (유한한 모집단 M에서 N개를 무작위 비복원 추출할 때, 그 중 성공인 n개를 얻을 확률분포)\n",
    "#e.g. 상자 속에 100개의 공이 있고, 그 중 20개가 빨간공, 80개가 파란공이라고 할 때, 10개를 뽑았을 때 빨간공이 5개일 확률\n",
    "from scipy.stats import hypergeom\n",
    "print(f'전체 100개 중 20개가 성공, 10개를 뽑았을 때 5개가 성공할 확률: {hypergeom.pmf(k=5, M=100, n=20, N=10):.4f}')\n",
    "print(f'전체 100개 중 20개가 성공, 10개를 뽑았을 때 5개 이하가 성공할 확률: {hypergeom.cdf(k=5, M=100, n=20, N=10):.4f}')\n",
    "print(f'전체 100개 중 20개가 성공, 10개를 뽑았을 때 성공 횟수 기댓값: {hypergeom.stats(M=100, n=20, N=10)[0]:.4f}, 분산: {hypergeom.stats(M=100, n=20, N=10)[1]:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.6 포아송 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 발생 빈도가 3일 때, 5번 발생할 확률: 0.1008\n",
      "평균 발생 빈도가 3일 때, 5번 이하로 발생할 확률: 0.9161\n",
      "평균 발생 빈도가 3일 때, 발생 횟수의 기댓값: 3.0000, 분산: 3.0000\n"
     ]
    }
   ],
   "source": [
    "# 포아송 분포 (단위 시간/공간에서 발생하는 사건의 횟수)\n",
    "# e.g. 하루 평균 3건의 사고가 발생하는 교차로에서, 하루에 실제로 5건의 사고가 발생할 확률.\n",
    "from scipy.stats import poisson\n",
    "print(f'평균 발생 빈도가 3일 때, 5번 발생할 확률: {poisson.pmf(k=5, mu=3):.4f}')\n",
    "print(f'평균 발생 빈도가 3일 때, 5번 이하로 발생할 확률: {poisson.cdf(k=5, mu=3):.4f}')\n",
    "print(f'평균 발생 빈도가 3일 때, 발생 횟수의 기댓값: {poisson.stats(mu=3)[0]:.4f}, 분산: {poisson.stats(mu=3)[1]:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연속 확률분포"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.7 균일 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1~6 사이의 숫자가 나올 확률이 동일한 주사위를 던졌을 때, 숫자 2가 나올 확률 : 0.1667\n"
     ]
    }
   ],
   "source": [
    "# 균일 분포 (지정된 범위 내에서 모든 값이 나올 확률이 동일한 분포)\n",
    "# e.g. 1~6 사이의 숫자가 나올 확률이 동일한 주사위를 던졌을 때, 1~6 사이의 숫자가 나올 확률\n",
    "from scipy.stats import uniform\n",
    "print(f'1~6 사이의 숫자가 나올 확률이 동일한 주사위를 던졌을 때, 숫자 2가 나올 확률 : {uniform.pdf(x=2, loc=1, scale=6):.4f}') # loc: 시작점, scale: 범위, x: 확률변수"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.8 정규 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균이 2이고 표준편차가 3인 정규분포에서, 1~3 사이의 값이 나올 확률: 0.2611\n",
      "평균이 2이고 표준편차가 3인 정규분포에서 랜덤으로 하나를 뽑은 숫자: 1.9263122078179824\n",
      "평균이 2이고 표준편차가 3인 정규분포에서, 1이하의 값이 나올 확률: 0.3694\n"
     ]
    }
   ],
   "source": [
    "# 정규 분포 (평균과 표준편차로 모양이 결정되는 종 모양의 분포)\n",
    "# e.g. 평균이 2이고 표준편차가 3인 정규분포에서, 1~3 사이의 값이 나올 확률\n",
    "from scipy.stats import norm\n",
    "print(f'평균이 2이고 표준편차가 3인 정규분포에서, 1~3 사이의 값이 나올 확률: {norm.cdf(x=3, loc=2, scale=3) - norm.cdf(x=1, loc=2, scale=3):.4f}') # loc: 평균, scale: 표준편차, x: 확률변수\n",
    "print(f'평균이 2이고 표준편차가 3인 정규분포에서 랜덤으로 하나를 뽑은 숫자: {norm.rvs(loc=2, scale=3, size=1)[0]}') # loc: 평균, scale: 표준편차, size: 샘플링 개수\n",
    "print(f'평균이 2이고 표준편차가 3인 정규분포에서, 1이하의 값이 나올 확률: {norm.cdf(x=1, loc=2, scale=3):.4f}') # loc: 평균, scale: 표준편차, x: 확률변수"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.9 표준정규분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균이 0이고 표준편차가 1인 정규분포에서, -1~1 사이의 값이 나올 확률: 0.6827\n"
     ]
    }
   ],
   "source": [
    "# 표준정규분포 (평균이 0이고 표준편차가 1인 정규분포)\n",
    "# e.g. 평균이 0이고 표준편차가 1인 정규분포에서, -1~1 사이의 값이 나올 확률\n",
    "from scipy.stats import norm\n",
    "print(f'평균이 0이고 표준편차가 1인 정규분포에서, -1~1 사이의 값이 나올 확률: {norm.cdf(x=1, loc=0, scale=1) - norm.cdf(x=-1, loc=0, scale=1):.4f}') # loc: 평균, scale: 표준편차, x: 확률변수"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.10 지수 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 다음 버스가 도착하는데 걸리는 시간이 5분일 확률: 0.0607\n",
      "평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 다음 버스가 도착하는데 걸리는 시간이 5분 이하일 확률: 0.3935\n",
      "평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 다음 버스가 도착하는데 걸리는 시간의 기댓값: 10.0000, 분산: 100.0000\n"
     ]
    }
   ],
   "source": [
    "# 지수분포 (포아송 분포가 단위 시간내 발생하는 사건의 횟수라면, 지수분포는 한 번의 사건이 발생하는데 걸리는 시간)\n",
    "# e.g. 평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 다음 버스가 도착하는데 걸리는 시간이 5분일 확률\n",
    "from scipy.stats import expon\n",
    "print(f'평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 다음 버스가 도착하는데 걸리는 시간이 5분일 확률: {expon.pdf(x=5, loc=0, scale=10):.4f}') # loc: 시작점, scale: 평균, x: 확률변수\n",
    "print(f'평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 다음 버스가 도착하는데 걸리는 시간이 5분 이하일 확률: {expon.cdf(x=5, loc=0, scale=10):.4f}') # loc: 시작점, scale: 평균, x: 확률변수\n",
    "print(f'평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 다음 버스가 도착하는데 걸리는 시간의 기댓값: {expon.stats(loc=0, scale=10)[0]:.4f}, 분산: {expon.stats(loc=0, scale=10)[1]:.4f}') # loc: 시작점, scale: 평균"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.11 감마 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 2개의 버스가 도착하는데 걸리는 시간이 15분일 확률: 0.0335\n",
      "평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 2개의 버스가 도착하는데 걸리는 시간이 15분 이하일 확률: 0.4422\n"
     ]
    }
   ],
   "source": [
    "# 감마분포 (지수분포의 확장으로, a번의 사건이 발생할 때까지 걸리는 시간의 분포)\n",
    "# e.g. 평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 2개의 버스가 도착하는데 걸리는 시간이 15분일 확률\n",
    "from scipy.stats import gamma\n",
    "print(f'평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 2개의 버스가 도착하는데 걸리는 시간이 15분일 확률: {gamma.pdf(x=15, a=2, loc=0, scale=10):.4f}') # loc: 시작점, scale: 평균, x: 확률변수, a: 형상 파라미터(2개의 버스)\n",
    "print(f'평균 대기시간이 10분인 버스가 정류장에 도착했을 때, 2개의 버스가 도착하는데 걸리는 시간이 15분 이하일 확률: {gamma.cdf(x=15, a=2, loc=0, scale=10):.4f}') # loc: 시작점, scale: 평균, x: 확률변수, a: 형상 파라미터(2개의 버스)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
